{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7181633,"sourceType":"datasetVersion","datasetId":4151045},{"sourceId":7181763,"sourceType":"datasetVersion","datasetId":4151153}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, concatenate\nfrom tensorflow.python.client import device_lib\n\nc51= \"/kaggle/input/resultados12-csv/resultadosdata13.csv\"\n\n# Leer el DataFrame\ndf = pd.read_csv(c51)\n\ndf['Día'] = pd.to_datetime(df['Día'])\n\n# Define la longitud de la secuencia (por ejemplo, 7 días)\nlongitud_secuencia = 7\n\n# Crear un nuevo DataFrame para almacenar las secuencias temporales\ndf_secuencias = pd.DataFrame(columns=['Latitud', 'Longitud', 'Secuencia_Accidentes'])\n\n# Recorrer cada ubicación única en el conjunto de datos\nfor key, group in df.groupby(['Latitud', 'Longitud']):\n    latitud, longitud = key\n\n    # Ordenar por fecha\n    group = group.sort_values(by='Día')\n\n    # Crear secuencias temporales\n    secuencias_accidentes = []\n    for i in range(len(group) - longitud_secuencia + 1):\n        secuencia = group.iloc[i:i + longitud_secuencia]['Accidentes'].values\n        secuencias_accidentes.append(secuencia)\n\n    # Crear el DataFrame de secuencias\n    df_temporal = pd.DataFrame({\n        'Latitud': [latitud] * len(secuencias_accidentes),\n        'Longitud': [longitud] * len(secuencias_accidentes),\n        'Secuencia_Accidentes': secuencias_accidentes\n    })\n\n    # Concatenar al DataFrame principal\n    df_secuencias = pd.concat([df_secuencias, df_temporal], ignore_index=True)\n\n# Convertir las secuencias a tensores numpy\ntensores_accidentes = np.array(df_secuencias['Secuencia_Accidentes'].tolist())\ntensores_coords = df_secuencias[['Latitud', 'Longitud']].to_numpy()\n\n# Asegurar que los tensores de accidentes tengan la forma correcta\ntensores_accidentes = tensores_accidentes.reshape(tensores_accidentes.shape[0], longitud_secuencia, 1)\n\n# Verificar las formas de los tensores\nprint(\"Tensor de Secuencias de Accidentes:\", tensores_accidentes.shape)\nprint(\"Tensor de Coordenadas:\", tensores_coords.shape)\n\n# Paso 1: División de los Datos\nX_train, X_temp, y_train, y_temp = train_test_split(tensores_accidentes, tensores_coords, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Asegurar que las coordenadas estén divididas de la misma manera que las secuencias de accidentes\ncoords_train, coords_temp, _, _ = train_test_split(tensores_coords, tensores_coords, test_size=0.3, random_state=42)\ncoords_val, coords_test, _, _ = train_test_split(coords_temp, coords_temp, test_size=0.5, random_state=42)\n\nprint(\"Conjunto de Entrenamiento Coords:\", coords_train.shape)\nprint(\"Conjunto de Validación Coords:\", coords_val.shape)\nprint(\"Conjunto de Prueba Coords:\", coords_test.shape)\n\n# Normalizar los datos de entrada\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\nX_val_scaled = scaler.transform(X_val.reshape(-1, 1)).reshape(X_val.shape)\nX_test_scaled = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n\n# Verificar las GPUs disponibles\nprint(device_lib.list_local_devices())\n\n# Configurar TensorFlow para usar GPU\nimport tensorflow as tf\n\nphysical_devices = tf.config.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n# Definir tensores de entrada\ninput_sequence = Input(shape=(longitud_secuencia, 1), name='input_sequence')\n\n# Capas LSTM para procesar secuencias temporales con regularización Dropout\nlstm_output1 = LSTM(units=500, activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_sequence)\nlstm_output2 = LSTM(units=500, activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(lstm_output1)\nlstm_output3 = LSTM(units=500, activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(lstm_output2)\nlstm_output4 = LSTM(units=500, activation='tanh', dropout=0.2, recurrent_dropout=0.2)(lstm_output3)\n\n# Capa Dense después de la capa LSTM con regularización Dropout\nfc_layer1 = Dense(200, activation='relu')(lstm_output4)\nfc_layer1 = Dropout(0.2)(fc_layer1)\n\n# Capa de entrada para las coordenadas\ninput_coords = Input(shape=(2,), name='input_coords')\n\n# Concatenar salida de la capa Dropout y entrada de coordenadas\nmerged = concatenate([fc_layer1, input_coords])\n\n# Capa densa después de la concatenación con regularización Dropout\nfc_layer2 = Dense(200, activation='relu')(merged)\nfc_layer2 = Dropout(0.2)(fc_layer2)\n\n# Capa de salida\noutput_layer = Dense(1, activation='linear', name='output')(fc_layer2)\n\n# Compilar el modelo\nmodel = Model(inputs=[input_sequence, input_coords], outputs=output_layer)\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n\n# Resumen del modelo\nmodel.summary()\n\n# Entrenar el modelo\nhistory = model.fit([X_train_scaled, coords_train], y_train, epochs=20, batch_size=32, validation_data=([X_val_scaled, coords_val], y_val))\n\n# Evaluar en el conjunto de prueba\ntest_loss, test_mae, test_mse = model.evaluate([X_test_scaled, coords_test], y_test)\nprint(f\"Pérdida en el conjunto de prueba: {test_loss}\")\nprint(f\"MAE en el conjunto de prueba: {test_mae}\")\nprint(f\"MSE en el conjunto de prueba: {test_mse}\")","metadata":{"_uuid":"d5363d14-7951-4ccc-ad2c-e1e2938eba74","_cell_guid":"4a0f416d-50c0-4df6-beb3-115c6f17c9c9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-12T07:42:37.255684Z","iopub.execute_input":"2023-12-12T07:42:37.256044Z","iopub.status.idle":"2023-12-12T10:56:53.418465Z","shell.execute_reply.started":"2023-12-12T07:42:37.256019Z","shell.execute_reply":"2023-12-12T10:56:53.417501Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/3154728512.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  df_secuencias = pd.concat([df_secuencias, df_temporal], ignore_index=True)\n","output_type":"stream"},{"name":"stdout","text":"Tensor de Secuencias de Accidentes: (245250, 7, 1)\nTensor de Coordenadas: (245250, 2)\nConjunto de Entrenamiento Coords: (171675, 2)\nConjunto de Validación Coords: (36787, 2)\nConjunto de Prueba Coords: (36788, 2)\n[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 2409714367897045742\nxla_global_id: -1\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 16120545280\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 13296378107127301180\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\nxla_global_id: 416903419\n]\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_sequence (InputLayer  [(None, 7, 1)]               0         []                            \n )                                                                                                \n                                                                                                  \n lstm_4 (LSTM)               (None, 7, 500)               1004000   ['input_sequence[0][0]']      \n                                                                                                  \n lstm_5 (LSTM)               (None, 7, 500)               2002000   ['lstm_4[0][0]']              \n                                                                                                  \n lstm_6 (LSTM)               (None, 7, 500)               2002000   ['lstm_5[0][0]']              \n                                                                                                  \n lstm_7 (LSTM)               (None, 500)                  2002000   ['lstm_6[0][0]']              \n                                                                                                  \n dense_2 (Dense)             (None, 200)                  100200    ['lstm_7[0][0]']              \n                                                                                                  \n dropout_2 (Dropout)         (None, 200)                  0         ['dense_2[0][0]']             \n                                                                                                  \n input_coords (InputLayer)   [(None, 2)]                  0         []                            \n                                                                                                  \n concatenate_1 (Concatenate  (None, 202)                  0         ['dropout_2[0][0]',           \n )                                                                   'input_coords[0][0]']        \n                                                                                                  \n dense_3 (Dense)             (None, 200)                  40600     ['concatenate_1[0][0]']       \n                                                                                                  \n dropout_3 (Dropout)         (None, 200)                  0         ['dense_3[0][0]']             \n                                                                                                  \n output (Dense)              (None, 1)                    201       ['dropout_3[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 7151001 (27.28 MB)\nTrainable params: 7151001 (27.28 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\nEpoch 1/20\n5365/5365 [==============================] - 598s 109ms/step - loss: 4580.3330 - mae: 67.6336 - mse: 4580.3330 - val_loss: 4576.4604 - val_mae: 67.6400 - val_mse: 4576.4604\nEpoch 2/20\n5365/5365 [==============================] - 580s 108ms/step - loss: 4578.0083 - mae: 67.6336 - mse: 4578.0083 - val_loss: 4576.4443 - val_mae: 67.6400 - val_mse: 4576.4443\nEpoch 3/20\n5365/5365 [==============================] - 582s 109ms/step - loss: 4577.7646 - mae: 67.6338 - mse: 4577.7646 - val_loss: 4576.4531 - val_mae: 67.6400 - val_mse: 4576.4531\nEpoch 4/20\n5365/5365 [==============================] - 591s 110ms/step - loss: 4577.5552 - mae: 67.6337 - mse: 4577.5552 - val_loss: 4576.4321 - val_mae: 67.6400 - val_mse: 4576.4321\nEpoch 5/20\n5365/5365 [==============================] - 590s 110ms/step - loss: 4577.3633 - mae: 67.6337 - mse: 4577.3633 - val_loss: 4576.4561 - val_mae: 67.6400 - val_mse: 4576.4561\nEpoch 6/20\n5365/5365 [==============================] - 579s 108ms/step - loss: 4577.1753 - mae: 67.6337 - mse: 4577.1753 - val_loss: 4576.4551 - val_mae: 67.6400 - val_mse: 4576.4551\nEpoch 7/20\n5365/5365 [==============================] - 577s 108ms/step - loss: 4576.9863 - mae: 67.6338 - mse: 4576.9863 - val_loss: 4576.5151 - val_mae: 67.6400 - val_mse: 4576.5151\nEpoch 8/20\n5365/5365 [==============================] - 579s 108ms/step - loss: 4576.8276 - mae: 67.6336 - mse: 4576.8276 - val_loss: 4576.5098 - val_mae: 67.6400 - val_mse: 4576.5098\nEpoch 9/20\n5365/5365 [==============================] - 584s 109ms/step - loss: 4576.6743 - mae: 67.6335 - mse: 4576.6743 - val_loss: 4576.4570 - val_mae: 67.6400 - val_mse: 4576.4570\nEpoch 10/20\n5365/5365 [==============================] - 577s 107ms/step - loss: 4576.5430 - mae: 67.6337 - mse: 4576.5430 - val_loss: 4576.4604 - val_mae: 67.6400 - val_mse: 4576.4604\nEpoch 11/20\n5365/5365 [==============================] - 575s 107ms/step - loss: 4576.4155 - mae: 67.6337 - mse: 4576.4155 - val_loss: 4576.4663 - val_mae: 67.6400 - val_mse: 4576.4663\nEpoch 12/20\n5365/5365 [==============================] - 576s 107ms/step - loss: 4576.3110 - mae: 67.6336 - mse: 4576.3110 - val_loss: 4576.4644 - val_mae: 67.6400 - val_mse: 4576.4644\nEpoch 13/20\n5365/5365 [==============================] - 575s 107ms/step - loss: 4576.1973 - mae: 67.6336 - mse: 4576.1973 - val_loss: 4576.4683 - val_mae: 67.6400 - val_mse: 4576.4683\nEpoch 14/20\n5365/5365 [==============================] - 581s 108ms/step - loss: 4576.1182 - mae: 67.6337 - mse: 4576.1182 - val_loss: 4576.5317 - val_mae: 67.6400 - val_mse: 4576.5317\nEpoch 15/20\n5365/5365 [==============================] - 580s 108ms/step - loss: 4576.0317 - mae: 67.6338 - mse: 4576.0317 - val_loss: 4576.4780 - val_mae: 67.6400 - val_mse: 4576.4780\nEpoch 16/20\n5365/5365 [==============================] - 579s 108ms/step - loss: 4575.9624 - mae: 67.6335 - mse: 4575.9624 - val_loss: 4576.5088 - val_mae: 67.6400 - val_mse: 4576.5088\nEpoch 17/20\n5365/5365 [==============================] - 581s 108ms/step - loss: 4575.8989 - mae: 67.6336 - mse: 4575.8989 - val_loss: 4576.5229 - val_mae: 67.6400 - val_mse: 4576.5229\nEpoch 18/20\n5365/5365 [==============================] - 578s 108ms/step - loss: 4575.8472 - mae: 67.6336 - mse: 4575.8472 - val_loss: 4576.4878 - val_mae: 67.6400 - val_mse: 4576.4878\nEpoch 19/20\n5365/5365 [==============================] - 580s 108ms/step - loss: 4575.8188 - mae: 67.6337 - mse: 4575.8188 - val_loss: 4576.4932 - val_mae: 67.6400 - val_mse: 4576.4932\nEpoch 20/20\n5365/5365 [==============================] - 572s 107ms/step - loss: 4575.7749 - mae: 67.6337 - mse: 4575.7749 - val_loss: 4576.4995 - val_mae: 67.6400 - val_mse: 4576.4995\n1150/1150 [==============================] - 12s 10ms/step - loss: 4575.8159 - mae: 67.6349 - mse: 4575.8159\nPérdida en el conjunto de prueba: 4575.81591796875\nMAE en el conjunto de prueba: 67.6348648071289\nMSE en el conjunto de prueba: 4575.81591796875\n","output_type":"stream"}]}]}